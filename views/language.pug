extends /templates/simulation-template

block title
	- const title = "Natural Language Processing"

block required_scripts
	- const required_scripts = ["language-sketch.js"];
	script(src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs")
	script(src="https://cdn.jsdelivr.net/npm/@tensorflow-models/universal-sentence-encoder")


block nav_info
	- const current_page = "Language";
	- const prev_page = {name: "Genetic Algorithms", link: "/genetic"};;
	- const next_page = {name: "Conclusion", link: "/conclusion"};

block summary
	p A defining aspect of humanity is our ability to use language.  Human language is extremely complicated and the rules of communication are almost impossible to program directly.  Artificial intelligence has been used to model language in a subfield called natural language processing (NLP).  NLP is extremely prevalent in the world today, involving digital assistants such as Siri and Alexa, translation services such as Google Translate, moderation such as flagging offensive comments on Instagram, customer service chatbots on websites, and more.  Many people interact with some form of NLP on a daily basis.
	p This subfield would require a whole other project to dive into completely, but this simulation gives an example of one aspect of NLP.  The model in the simulation, taken from <a href="https://www.tensorflow.org/js/models" class="link-secondary">here</a>, is the Universal Sentence Encoder.  This model transforms a sentence of any length in to a \(512\)-dimensional embedding.  This is important because many models need a fixed length input, while sentences are variable in length.  The Universal Sentence Encoder solves this problem by turning any sentence into a fixed length vector.
	p This model is also important because it has been trained to keep sentences with similar meaning close to each other.  This means that an NLP model which uses the Universal Sentence Encoder to create input will have a huge advantage because sentences will be mapped in a way that will make training much easier.  This aspect of the Universal Sentence Encoder is what the simulation demonstrates.  It is run on each of the sentences, generating two \(512\)-dimensional embeddings.  Then, a vector dot product is performed on these values, which outputs numbers closer to \(1\) for close vectors and numbers closer to \(0\) for far vectors.

block instructions
	.col.fw-bold Click “Load” to load TensorFlow’s pre-trained model (this may take a while).  Afterwards, click on the sentences to edit them and click “Compare” to calculate the similarity between the sentences.
	.col-3.d-flex.justify-content-center
		.btn-toolbar
			button.btn.btn-primary#load-model(onclick="load_model()") Load