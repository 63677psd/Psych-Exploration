extends /templates/simulation-template

block title
	- const title = "Feedforward Neural Networks and Backpropogation"

block required_scripts
	- const required_scripts = ["draw-nn.js", "feedforward-sketch.js"];
	script(src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs")

block nav_info
	- const current_page = "Neural Networks";
	- const prev_page = {name: "Perceptron", link: "/perceptron"};
	- const next_page = {name:"Convolutional NN", link: "/convolutional"};

block summary
	p Just as the brain is made up of interconnected neurons, artificial neural networks are made up of interconnected perceptrons.  The most common type of neural network is a feedforward neural network, which means that the perceptrons are connected in one direction.  A feedforward neural network can be split into layers.  The first layer in a neural network is the input layer, which is changed depending on the specific inputs fed to the network.  The last layer is the output layer, which is the result produced by the neural network.  Anything in between is called a hidden layer because it is never directly interacted with when using a neural network.
	p Consecutive layers of a neural network can be calculated by evaluating each of the perceptrons in that layer using the previous layer as inputs.  The weights and biases of each perceptron can be organized into matrices, which speeds up computation because computers (especially their GPUs) are extremely good at performing computations with matrices.  This process starts with the input layer, feeding forward to every layer until the output is reached.
	p However, to make a neural network actually produce an intelligent result, the weights and biases of each perceptron must be chosen carefully.  This can be done using a supervised learning algorithm called backpropogation.  In backpropogation, labeled data is inputted to the neural network.  The error of the network is calculated and then weights and biases are slightly adjusted to lower the error.  This is done many times for a huge amount of data, and the neural network eventually develops a low enough error that it can make accurate predictions even on inputs it has never seen before.
	p Once the simulation is initialized, a simple feedforward neural network is created.  The input layer of this neural network has two nodes, there are two hidden layers each with six nodes, and the output layer has one node.  The outputs of each perceptron are not shown in this simulation but the weights and biases are depicted identically to how they were on the last page.  The simulation will begin training the neural network on generated data, and two values will be shown in the top left of the simulation.  First, “Epochs” is the number of times the neural network has trained on the data.  To get good results, many epochs of training are needed.  The second value is the “Loss,” which is a measure of how bad the neural network is at modeling the data.  When the loss decreases, the neural network is performing better.

block instructions
	.col.fw-bold Click “Initialize” to generate a new neural network and begin training.  After the training has began, the refresh button can be pressed to start over.
	.col-3.d-flex.justify-content-center
		.btn-toolbar
			button.btn.btn-primary.m-2#start(onclick="start()") Initialize
			button.btn.btn-warning.m-2.p-1#restart(onclick="restart_sketch()" style="display:none")
				i.bi.bi-arrow-repeat.h4