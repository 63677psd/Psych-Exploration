<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"><script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css"><style type="text/css">html {
	height: 100%;
	overflow-x: hidden;
}
.bg-color {
	background: #7CB9E8;
}
.btn-toolbar {
	height: 20px;
}

</style><script src="https://code.jquery.com/jquery-3.6.0.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.4.0/p5.min.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css" rel="stylesheet"><script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script src="/static/scripts/perceptron-sketch.js"></script><title>Simulating Intelligence</title></head><body><div class="container-fluid d-flex flex-column" style="min-height:100vh"><div class="row bg-color p-5 text-center"><h1>Perceptron</h1></div><div class="row"><div class="col px-0"><nav class="navbar navbar-expand-md bg-dark navbar-dark"><div class="container-fluid px-2"><ul class="navbar-nav"><li class="nav-item"><a class="nav-link" href="/intro">Introduction</a></li><li class="navitem dropdown"><a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown">First Steps</a><ul class="dropdown-menu"><li><a class="dropdown-item" href="/algorithms">Algorithms</a></li><li><a class="dropdown-item" href="/heuristics">Heuristics</a></li></ul></li><li class="navitem dropdown"><a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown">Learning</a><ul class="dropdown-menu"><li><a class="dropdown-item" href="/supervised-unsupervised">Supervised vs. Unsupervised</a></li><li><a class="dropdown-item" href="/reinforcement">Reinforcement Learning</a></li></ul></li><li class="navitem dropdown"><a class="nav-link dropdown-toggle active" href="#" role="button" data-bs-toggle="dropdown">Neural Networks</a><ul class="dropdown-menu"><li><a class="dropdown-item" href="/perceptron">Perceptron</a></li><li><a class="dropdown-item" href="/feedforward">Feedforward NN</a></li><li><a class="dropdown-item" href="/convolutional">Convolutional NN</a></li><li><a class="dropdown-item" href="/object-detection">Object Detection</a></li></ul></li><li class="nav-item"><a class="nav-link" href="/genetic">Genetic Algorithms</a></li><li class="nav-item"><a class="nav-link" href="/language">Language</a></li><li class="nav-item"><a class="nav-link" href="/conclusion">Conclusion</a></li></ul></div></nav></div></div><div class="row p-0"><div class="col p-0"><div class="container mt-3"><p>This page and the next three pages will cover artificial neural networks, which attempt to model the human brain to create intelligent behavior.  Neural networks have led to some of the most advanced intelligent behavior demonstrated by computers.</p><p>The brain is made up of interconnected neurons, each of which takes inputs through its dendrites and either fires or doesnâ€™t fire an output signal through its axon.  The inputs to the neuron can be either inhibitory or excitatory.  The inhibitory inputs try to inhibit the neuron from firing while the excitatory inputs try to cause the neuron to fire.  If the strength of the excitatory inputs exceeds the strength of the inhibitory inputs, the neuron will fire.</p><p>A computer model of a single neuron, called a perceptron, functions similarly.  Each input, \(x_i\), to the perceptron has a certain weight, \(w_i\), which is the amount of impact the input will have on the perceptron.  Positive weights increase the output of the perceptron while negative weights decrease its output.  Each perceptron also has a bias, \(b\), which is its predisposition to firing without any inputs.  A positive bias increases the perceptron output while a negative bias decreases it.  As an expression, the output of the perceptron is \[\sigma(b + \sum_i{w_i x_i})\] This means that to find the output of a perceptron, multiply each input by its weight and total the results.  Then, add the bias and pass this value to another function, \(\sigma\), which is called the activation function and is used to incorporate nonlinearity into the perceptron.  Later, when many perceptrons are combined into a network, this nonlinearity will be what allows robust models to be created.  Different activation functions can be used, but the one in the simulation is called the sigmoid function, which is defined as \[\sigma(x) = \frac{1}{1 + e^{-x}}\] Biological neurons can either fire or do nothing, there is no in between.  Perceptrons, however, can output any value in the range of the activation function.  The sigmoid function is a popular activation function because it maps negative values to numbers close to \(0\) and positive values to numbers close to \(1\), which for numbers of large enough magnitude is essentially the same as firing or not firing.</p><p>In the simulation below, lighter colored circles have a value close to \(0\) and darker colored circles have a value close to \(1\).  Inputs are on the left and the perceptron output is on the right. The weights are the arrows that connect circles and the bias is the arrow pointing down.  Green arrows are positive and red arrows are negative.  The magnitude of the weights/bias corresponds to the thickness of the arrow.</p></div><div class="container-xl border p-3 mt-3"><div class="row pb-2"><div class="col fw-bold">Move the mouse around the simulation to randomly generate new input values for the perceptron. Clicking the refresh button will randomize the weights and bias for the perceptron.</div><div class="col-3 d-flex justify-content-center"><div class="btn-toolbar"><button class="btn btn-warning m-2 p-1" onclick="restart_sketch()"><i class="bi bi-arrow-repeat h4"></i></button></div></div></div><div class="row"><div class="d-flex justify-content-center" id="sketch"></div></div><div class="row"><a class="link-dark" href="#" data-bs-toggle="modal" data-bs-target="#code-view">View Code</a></div></div><div class="modal fade" id="code-view" aria-hidden="true"><div class="modal-dialog modal-xl"><div class="modal-content"><div class="modal-header"><h4 class="modal-title">Code</h4><button class="btn-close" type="button" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="accordion"><div class="accordion-item"><h2 class="accordion-header"><button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#script0">perceptron-sketch.js</button></h2><div class="accordion-collapse collapse" id="script0"><div class="accordion-body"><pre><code id="code0"></code></pre></div></div></div><script>fetch("/static/scripts/perceptron-sketch.js")
	.then(response => response.text())
	.then(text => $("#code0").text(text))
	.then(x => hljs.highlightElement($("#code0")[0]));
</script></div></div><div class="modal-footer"><button class="btn btn-danger" type="button" data-bs-dismiss="modal">Close</button></div></div></div></div></div></div><div class="row align-items-end flex-fill"><div class="col"><div class="row mt-3"><div class="col-3 text-center"><a class="btn btn-outline-primary rounded-pill py-1 px-3" href="/reinforcement"><i class="bi bi-caret-left-fill"></i><span>Reinforcement Learning</span></a></div><div class="col-6"></div><div class="col-3 text-center"><a class="btn btn-outline-primary rounded-pill py-1 px-3" href="/feedforward"><span>Feedforward NN</span><i class="bi bi-caret-right-fill"></i></a></div></div><div class="row mt-3"><div class="col bg-color p-3"><span>Brady Bhalla, 2022</span></div></div></div></div></div></body></html>